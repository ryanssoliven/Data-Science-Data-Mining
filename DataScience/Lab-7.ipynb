{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa52c4fb-b8af-48a0-bf4e-16566914775a",
   "metadata": {},
   "source": [
    "1.1:\n",
    "\n",
    "In SVM what is the meaning of margin? Which are the equations of the two margin hyperplans H+ and H- ? (1 Mark)\n",
    "\n",
    "In SVM, the margin is the distance between the two margin hyperplanes, H+ and H-.\n",
    "\n",
    "Their equations are:\n",
    "\n",
    "H+: <w•x+>+b = 1 \n",
    "H-: <w•x->+b = -1\n",
    "\n",
    "where x+ and x- are the data points that are closest to the hyperplane <w•x->+b = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4009053-5715-4979-ae2f-6e78d99e71d6",
   "metadata": {},
   "source": [
    "1.2:\n",
    "\n",
    "Consider the three linearly separable two-dimensional input vectors in the following figure. Find the linear SVM that optimally separates the classes by maximizing the margin. (1 Mark)\n",
    "\n",
    "The linear SVM that optimally separate the classes by maximizing the margin is: -x + 2.0 = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3863a6-32e1-4210-8527-f4f1e9cbfa90",
   "metadata": {},
   "source": [
    "1.3:\n",
    "\n",
    "What is a kernel function? (1 Mark)\n",
    "\n",
    "The dot product is called the kernel and can be rewritten as: K(x, xi) = sum(x * xi)\n",
    "\n",
    "We may use kernel functions to implicitly map to a new feature space. The kernel must be equivalent to an inner product in some feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d570db-156e-4a21-91cd-79af551c7bd0",
   "metadata": {},
   "source": [
    "2:\n",
    "\n",
    "Compare Neural Network and SVM in Classification of heart disease data set in Python language. You can use the \n",
    "sklearn Python library to implement both Neural Networks and SVM. For SVM, build the model by changing the different \n",
    "kernels such as Linear, Gaussian and Sigmoid and note down the model accuracy. Similarly, use Stochastic Gradient \n",
    "Descent and Adam Gradient Descent to build the multi-layer Neural Network and note down the model accuracy for each. \n",
    "Finally, tell us which model performs better and why? (5 Marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82eae1d1-fc51-49e7-aae5-f1973be0aac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy Score: 65.57377049180327%\n"
     ]
    }
   ],
   "source": [
    "# SVM Implementation: Linear\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('heart-disease-dataset1.csv')\n",
    "\n",
    "# Convert the '?' to NaN\n",
    "df = df.replace('?','0')\n",
    "# Discard the data points that contain missing values\n",
    "#df = df.dropna()\n",
    "# Drop row duplicates\n",
    "#df = df.drop_duplicates()\n",
    "\n",
    "X = df.drop(['result'],axis=1)\n",
    "y = df['result']\n",
    "\n",
    "# Standardize the data\n",
    "X = scale(X)\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X, y.ravel(), test_size=0.2, stratify=y, random_state=25)\n",
    "sm = svm.SVC(kernel='linear')\n",
    "sm.fit(X_train_1, Y_train_1)\n",
    "y_pred = sm.predict(X_test_1)\n",
    "\n",
    "print(\"SVM Model Accuracy Score: {}%\".format(accuracy_score(Y_test_1, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b04152-7738-498a-9a8b-199a0563f8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy Score: 59.01639344262295%\n"
     ]
    }
   ],
   "source": [
    "# SVM Implementation: Gaussian\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('heart-disease-dataset1.csv')\n",
    "\n",
    "# Convert the '?' to NaN\n",
    "df = df.replace('?','0')\n",
    "# Discard the data points that contain missing values\n",
    "#df = df.dropna()\n",
    "# Drop row duplicates\n",
    "#df = df.drop_duplicates()\n",
    "\n",
    "X = df.drop(['result'],axis=1)\n",
    "y = df['result']\n",
    "\n",
    "# Standardize the data\n",
    "X = scale(X)\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X, y.ravel(), test_size=0.2, stratify=y, random_state=25)\n",
    "sm = svm.SVC(kernel='rbf')\n",
    "sm.fit(X_train_1, Y_train_1)\n",
    "y_pred = sm.predict(X_test_1)\n",
    "\n",
    "print(\"SVM Model Accuracy Score: {}%\".format(accuracy_score(Y_test_1, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc48a90-6f86-41ec-8b10-dacfeae23204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model Accuracy Score: 60.65573770491803%\n"
     ]
    }
   ],
   "source": [
    "# SVM Implementation: Sigmoid\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('heart-disease-dataset1.csv')\n",
    "\n",
    "# Convert the '?' to NaN\n",
    "df = df.replace('?','0')\n",
    "# Discard the data points that contain missing values\n",
    "#df = df.dropna()\n",
    "# Drop row duplicates\n",
    "#df = df.drop_duplicates()\n",
    "\n",
    "X = df.drop(['result'],axis=1)\n",
    "y = df['result']\n",
    "\n",
    "# Standardize the data\n",
    "X = scale(X)\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X, y.ravel(), test_size=0.2, stratify=y, random_state=25)\n",
    "sm = svm.SVC(kernel='sigmoid')\n",
    "sm.fit(X_train_1, Y_train_1)\n",
    "y_pred = sm.predict(X_test_1)\n",
    "\n",
    "print(\"SVM Model Accuracy Score: {}%\".format(accuracy_score(Y_test_1, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953a73a3-2db9-4a4b-8056-b7627d911010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model Accuracy Score: 63.934426229508205%\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Implementation: Stochastic Gradient Descent\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('heart-disease-dataset1.csv')\n",
    "\n",
    "# Convert the '?' to NaN\n",
    "df = df.replace('?','0')\n",
    "# Discard the data points that contain missing values\n",
    "#df = df.dropna()\n",
    "# Drop row duplicates\n",
    "#df = df.drop_duplicates()\n",
    "\n",
    "# Use exang as the target class\n",
    "# Chose exang instead of sex or fbs because it gave highest accuracy score\n",
    "X = df.drop(['result'],axis=1)\n",
    "y = df['result']\n",
    "\n",
    "# Standardize the data\n",
    "X = scale(X)\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X, y.ravel(), test_size=0.2, stratify=y, random_state=25)\n",
    "\n",
    "clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(1, ), random_state=1, max_iter=10000, activation='identity', learning_rate_init=0.01)\n",
    "clf.fit(X_train_1, Y_train_1)\n",
    "y_pred = clf.predict(X_test_1)\n",
    "\n",
    "for i in range(len(clf.coefs_)):\n",
    "    number_neurons_in_layer = clf.coefs_[i].shape[1]\n",
    "    for j in range(number_neurons_in_layer):\n",
    "        weights = clf.coefs_[i][:,j]\n",
    "\n",
    "print(\"Neural Network Model Accuracy Score: {}%\".format(accuracy_score(Y_test_1, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8261a4af-bc84-4801-a837-108006149c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Model Accuracy Score: 65.57377049180327%\n"
     ]
    }
   ],
   "source": [
    "# Neural Network Implementation: Adam Gradient Descent\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('heart-disease-dataset1.csv')\n",
    "\n",
    "# Convert the '?' to NaN\n",
    "df = df.replace('?','0')\n",
    "# Discard the data points that contain missing values\n",
    "#df = df.dropna()\n",
    "# Drop row duplicates\n",
    "#df = df.drop_duplicates()\n",
    "\n",
    "# Use exang as the target class\n",
    "# Chose exang instead of sex or fbs because it gave highest accuracy score\n",
    "X = df.drop(['result'],axis=1)\n",
    "y = df['result']\n",
    "\n",
    "# Standardize the data\n",
    "X = scale(X)\n",
    "\n",
    "X_train_1, X_test_1, Y_train_1, Y_test_1 = train_test_split(X, y.ravel(), test_size=0.2, stratify=y, random_state=25)\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(1, ), random_state=1, max_iter=10000, activation='identity', learning_rate_init=0.01)\n",
    "clf.fit(X_train_1, Y_train_1)\n",
    "y_pred = clf.predict(X_test_1)\n",
    "\n",
    "for i in range(len(clf.coefs_)):\n",
    "    number_neurons_in_layer = clf.coefs_[i].shape[1]\n",
    "    for j in range(number_neurons_in_layer):\n",
    "        weights = clf.coefs_[i][:,j]\n",
    "\n",
    "print(\"Neural Network Model Accuracy Score: {}%\".format(accuracy_score(Y_test_1, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13287b7-7bc0-4378-8a92-c0e7bf6c8b3a",
   "metadata": {},
   "source": [
    "Comparing scores, the Linear SVM model and the Adam Gradient Descent NN model are both the same and are higher than the other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267f362-f83f-43c4-8566-ce777486aebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
